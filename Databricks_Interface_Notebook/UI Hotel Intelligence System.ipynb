{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc7abed4-4dab-4ee7-96b9-d6e448aa5718",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "LIbraries (MUST RUN THIS CELL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "851697c1-2885-4893-a76f-2b9f151363b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Install UI and Embedding models\n",
    "%pip install gradio==3.50.2 sentence-transformers --quiet\n",
    "\n",
    "# 2. Install Utilities\n",
    "%pip install spark-nlp nltk duckduckgo-search python-dotenv\n",
    "\n",
    "# 3. Install LangChain Framework & Graph (Letting 'core' resolve automatically)\n",
    "%pip install langchain==0.3.14 langgraph==0.2.60\n",
    "\n",
    "# 4. Install LangChain Integrations (Letting 'pinecone-client' resolve automatically)\n",
    "%pip install langchain-google-genai==2.0.7 langchain-huggingface==0.1.2 langchain-pinecone==0.2.0 langchain-groq==0.2.2\n",
    "\n",
    "# 5. Apply changes\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1063c301-2329-40a2-9243-4e4f4ae441d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Hotel Intelligence System - Gradio Interface\n",
    "\n",
    "This interface provides an interactive way to query the Hotel Intelligence System using multiple AI agents.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Competitor Analysis**: Deep NLP analysis comparing your property's reviews vs similar properties across 20 topics\n",
    "- **Feature Impact Analysis**: Linear regression model identifying which features most impact ratings\n",
    "- **Market Intelligence**: Web scraping and sentiment analysis for competitive insights\n",
    "- **Review Analysis**: Topic-specific review analysis with evidence quotes\n",
    "\n",
    "## Performance Notes\n",
    "\n",
    "- In order to check if a reponse has arrived - please click on \"Check Status\" button.\n",
    "- NLP and LR analyses take approximately **7 minutes each**\n",
    "- Charts are automatically generated and linked in responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afdb448a-616c-4557-8e44-b309f5132690",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gradio Chat Interface for Databricks\n",
    "\"\"\"\n",
    "\n",
    "import threading\n",
    "import time\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "import builtins\n",
    "import gradio as gr\n",
    "from PIL import Image as PILImage\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "# Get the current user's email dynamically\n",
    "current_user = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "# Construct the base path dynamically\n",
    "base_path = f\"/Workspace/Users/{current_user}/hotel-intelligence-system\"\n",
    "sys.path.insert(0, f\"{base_path}\")\n",
    "sys.path.insert(0, f\"{base_path}/agents\")\n",
    "\n",
    "builtins.dbutils = dbutils  # Required for Databricks\n",
    "\n",
    "# ==============================================\n",
    "# CONFIGURATION\n",
    "# ==============================================\n",
    "\n",
    "HOTEL_ID = \"ABB_40458495\"\n",
    "HOTEL_NAME = \"Rental unit in Broadbeach\"  \n",
    "CITY = \"Broadbeach\"\n",
    "\n",
    "from agents.coordinator import LangGraphCoordinator\n",
    "coordinator = LangGraphCoordinator(HOTEL_ID, HOTEL_NAME, CITY)\n",
    "state = coordinator.get_initial_state()\n",
    "\n",
    "# Thread-safe global storage\n",
    "captured_charts = []\n",
    "state_lock = threading.Lock()\n",
    "job_lock = threading.Lock()\n",
    "\n",
    "current_job = {\n",
    "    \"running\": False,\n",
    "    \"progress\": \"\",\n",
    "    \"result\": None,\n",
    "    \"error\": None,\n",
    "    \"start_time\": None,\n",
    "    \"thread_id\": None\n",
    "}\n",
    "\n",
    "# ==============================================\n",
    "# CHART CAPTURE PATCH \n",
    "# ==============================================\n",
    "\n",
    "_patched_modules = []\n",
    "\n",
    "def _capture_charts(result):\n",
    "    global captured_charts\n",
    "    \n",
    "    charts = result.get(\"charts\", {})\n",
    "    if not charts:\n",
    "        ui_artifacts = result.get(\"ui_artifacts\", {})\n",
    "        charts = ui_artifacts.get(\"charts\", {}) if isinstance(ui_artifacts, dict) else {}\n",
    "\n",
    "    captured_charts = []\n",
    "    for name, b64 in charts.items():\n",
    "        if isinstance(b64, dict):\n",
    "            b64 = b64.get(\"data\") or b64.get(\"base64\") or b64.get(\"image\")\n",
    "        \n",
    "        if b64 and isinstance(b64, str):\n",
    "            try:\n",
    "                img = PILImage.open(BytesIO(base64.b64decode(b64)))\n",
    "                captured_charts.append(img)\n",
    "            except Exception as e:\n",
    "                pass  # Silently fail on bad image data to prevent crash\n",
    "\n",
    "def _patch_lr(module, module_name):\n",
    "    original = module.run_lr_analysis\n",
    "\n",
    "    def patched_lr(hotel_id, timeout_seconds=1200):\n",
    "        result = original(hotel_id, timeout_seconds)\n",
    "        _capture_charts(result)\n",
    "        return result\n",
    "\n",
    "    module.run_lr_analysis = patched_lr\n",
    "    _patched_modules.append(module_name)\n",
    "\n",
    "try:\n",
    "    import databricks_tools\n",
    "    _patch_lr(databricks_tools, \"databricks_tools\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    from agents import databricks_tools as agents_databricks_tools\n",
    "    _patch_lr(agents_databricks_tools, \"agents.databricks_tools\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "\n",
    "# ==============================================\n",
    "# ASYNC JOB HANDLING \n",
    "# ==============================================\n",
    "\n",
    "def run_analysis_thread(query: str, thread_state: dict):\n",
    "    global captured_charts, current_job\n",
    "    \n",
    "    with job_lock:\n",
    "        current_job[\"running\"] = True\n",
    "        current_job[\"progress\"] = \"Initializing...\"\n",
    "        current_job[\"result\"] = None\n",
    "        current_job[\"error\"] = None\n",
    "        current_job[\"start_time\"] = time.time()\n",
    "        current_job[\"thread_id\"] = threading.current_thread().ident\n",
    "        captured_charts = []\n",
    "    \n",
    "    result_state = None\n",
    "    \n",
    "    try:\n",
    "        with job_lock:\n",
    "            current_job[\"progress\"] = \"Extracting entities from query...\"\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        with job_lock:\n",
    "            current_job[\"progress\"] = \"Routing to specialist agent(s)...\"\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "        with job_lock:\n",
    "            current_job[\"progress\"] = \"Agent working (may take 15-20 min for deep analysis)...\"\n",
    "        \n",
    "        start_exec = time.time()\n",
    "        response, result_state = coordinator.run(query, thread_state)\n",
    "        exec_time = time.time() - start_exec\n",
    "        \n",
    "        with job_lock:\n",
    "            current_job[\"result\"] = response\n",
    "            current_job[\"progress\"] = f\"Complete! (took {exec_time/60:.1f} min)\"\n",
    "        \n",
    "        with state_lock:\n",
    "            global state\n",
    "            state = result_state\n",
    "            \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        \n",
    "        with job_lock:\n",
    "            current_job[\"error\"] = str(e)\n",
    "            current_job[\"progress\"] = f\"Error: {str(e)[:100]}\"\n",
    "    \n",
    "    finally:\n",
    "        with job_lock:\n",
    "            current_job[\"running\"] = False\n",
    "\n",
    "\n",
    "def start_analysis(message: str, history: list):\n",
    "    global current_job, state\n",
    "    \n",
    "    if not message.strip():\n",
    "        return \"\", history, [], \"‚ö†Ô∏è Please enter a question\"\n",
    "    \n",
    "    with job_lock:\n",
    "        if current_job[\"running\"]:\n",
    "            elapsed = int(time.time() - current_job[\"start_time\"]) if current_job[\"start_time\"] else 0\n",
    "            return \"\", history, [], f\"‚è≥ Analysis already in progress... ({elapsed}s)\\n{current_job['progress']}\"\n",
    "    \n",
    "    history = history + [(message, \"‚è≥ Processing... This may take 15-20 minutes for deep analysis.\\n\\nClick 'Check Status' to see progress.\")]\n",
    "    \n",
    "    with state_lock:\n",
    "        thread_state = copy.deepcopy(state)\n",
    "    \n",
    "    thread = threading.Thread(\n",
    "        target=run_analysis_thread, \n",
    "        args=(message, thread_state),\n",
    "        name=f\"Analysis-{int(time.time())}\"\n",
    "    )\n",
    "    thread.daemon = True\n",
    "    thread.start()\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    return \"\", history, [], \"‚è≥ Analysis started in background...\"\n",
    "\n",
    "\n",
    "def check_status(history: list):\n",
    "    global current_job, captured_charts\n",
    "    \n",
    "    if not history:\n",
    "        return history, [], \"No analysis running\"\n",
    "    \n",
    "    with job_lock:\n",
    "        is_running = current_job[\"running\"]\n",
    "        progress = current_job[\"progress\"]\n",
    "        result = current_job[\"result\"]\n",
    "        error = current_job[\"error\"]\n",
    "        start_time = current_job[\"start_time\"]\n",
    "        thread_id = current_job[\"thread_id\"]\n",
    "    \n",
    "    elapsed = int(time.time() - start_time) if start_time else 0\n",
    "    mins, secs = divmod(elapsed, 60)\n",
    "    \n",
    "    if is_running:\n",
    "        progress_bar = \"‚ñà\" * min(20, elapsed // 30) + \"‚ñë\" * max(0, 20 - elapsed // 30)\n",
    "        status = f\"‚è≥ Running ({mins}m {secs}s elapsed)\\n[{progress_bar}]\\n\\nThread ID: {thread_id}\\nStatus: {progress}\"\n",
    "        return history, captured_charts, status\n",
    "    \n",
    "    elif result:\n",
    "        if history and history[-1][1] and history[-1][1].startswith(\"‚è≥\"):\n",
    "            history[-1] = (history[-1][0], result)\n",
    "        status = f\" Complete! ({mins}m {secs}s total)\\nüìä Charts: {len(captured_charts)}\\nClick 'Check Status' again to refresh charts.\"\n",
    "        return history, captured_charts, status\n",
    "    \n",
    "    elif error:\n",
    "        if history and history[-1][1] and history[-1][1].startswith(\"‚è≥\"):\n",
    "            history[-1] = (history[-1][0], f\" Error: {error}\")\n",
    "        status = f\" Error after {mins}m {secs}s\"\n",
    "        return history, captured_charts, status\n",
    "    \n",
    "    else:\n",
    "        return history, captured_charts, \"Ready - enter a question\"\n",
    "\n",
    "\n",
    "def clear_chat():\n",
    "    global state, current_job, captured_charts\n",
    "    \n",
    "    with state_lock:\n",
    "        state = coordinator.get_initial_state()\n",
    "    \n",
    "    with job_lock:\n",
    "        current_job = {\n",
    "            \"running\": False,\n",
    "            \"progress\": \"\",\n",
    "            \"result\": None,\n",
    "            \"error\": None,\n",
    "            \"start_time\": None,\n",
    "            \"thread_id\": None\n",
    "        }\n",
    "    \n",
    "    captured_charts = []\n",
    "    \n",
    "    return [], [], \"Cleared - ready for new questions\"\n",
    "\n",
    "\n",
    "# ==============================================\n",
    "# GRADIO INTERFACE\n",
    "# ==============================================\n",
    "\n",
    "with gr.Blocks(title=f\"Hotel Intelligence: {HOTEL_NAME}\") as demo:\n",
    "    gr.Markdown(f\"# Hotel Intelligence: {HOTEL_NAME}\")\n",
    "    gr.Markdown(f\"\"\"    \n",
    "    **Hotel:** {HOTEL_NAME} (ID: {HOTEL_ID})  \n",
    "    **City:** {CITY}\n",
    "    \"\"\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(height=400, label=\"Conversation\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        msg = gr.Textbox(\n",
    "            placeholder=\"Ask: 'What features should I improve to increase my rating?'\", \n",
    "            show_label=False, \n",
    "            scale=4\n",
    "        )\n",
    "        send_btn = gr.Button(\"Send\", variant=\"primary\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        check_btn = gr.Button(\"Check Status\", variant=\"secondary\")\n",
    "        clear_btn = gr.Button(\"Clear Chat\", variant=\"stop\")\n",
    "    \n",
    "    status_box = gr.Textbox(\n",
    "        label=\"Status\", \n",
    "        value=\"Ready - enter a question\",\n",
    "        interactive=False,\n",
    "        lines=5\n",
    "    )\n",
    "    \n",
    "    chart_gallery = gr.Gallery(\n",
    "        label=\"üìä Analysis Charts\", \n",
    "        columns=2, \n",
    "        height=300, \n",
    "        visible=True\n",
    "    )\n",
    "    \n",
    "    send_btn.click(fn=start_analysis, inputs=[msg, chatbot], outputs=[msg, chatbot, chart_gallery, status_box])\n",
    "    msg.submit(fn=start_analysis, inputs=[msg, chatbot], outputs=[msg, chatbot, chart_gallery, status_box])\n",
    "    check_btn.click(fn=check_status, inputs=[chatbot], outputs=[chatbot, chart_gallery, status_box])\n",
    "    clear_btn.click(fn=clear_chat, inputs=[], outputs=[chatbot, chart_gallery, status_box])\n",
    "\n",
    "demo.queue()\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5097114969539996,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "UI Hotel Intelligence System",
   "widgets": {
    "query": {
     "currentValue": "",
     "nuid": "8a25b41b-6e38-42fb-8140-5d812c92866f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Your Question:",
      "name": "query",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "Your Question:",
      "name": "query",
      "options": {
       "autoCreated": false,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
